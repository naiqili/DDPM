from torchvision import datasets, transforms
from torch.utils.data import Dataset, DataLoader
import numpy as np
from numpy import log, pi
import torch
import matplotlib.pyplot as plt
from torchvision.utils import make_grid
import time
import io
import tensorflow as tf


class MNISTDataset(Dataset):
    """
    Noisable MNIST dataset. element-wise uniform noise will be added to each item
    From Nice paper. 为了更符合高斯，但实际效果可能有限。
    """
    def __init__(self, noise=0.1, train=True):
        transform = transforms.Compose([
            transforms.ToTensor(),  # first, convert image to PyTorch tensor
            transforms.Normalize((0.1307,), (0.3081,))  # normalize inputs
        ])
        self.MNIST = datasets.MNIST(root='./data/mnist', train=train, transform=transform, download=True)

        self.noise = noise

    def __getitem__(self, index):
        data, target = self.MNIST[index]
        data = data + (torch.rand(data.size()) - 0.5) * self.noise
        # Your transformations here (or set it in CIFAR10)
        return data, target, index

    def __len__(self):
        return len(self.MNIST)


class AEMNISTDataset(Dataset):
    """
    Noisable AutoEncoded-MNIST dataset.
    1. element-wise uniform noise will be added to each image.
    2. an additional feature vector generated by a pretrained AutoEncoder will be returned.
    """
    def __init__(self, ae_model, N, noise=0.1, train=True, aex_file=None):
        transform = transforms.Compose([
            transforms.ToTensor(),  # first, convert image to PyTorch tensor
            transforms.Normalize((0.1307,), (0.3081,))  # normalize inputs
        ])
        self.MNIST = datasets.MNIST(root='./data/mnist', train=train, transform=transform, download=True)
        self.MNIST.data = self.MNIST.data[:N]
        self.targets = np.asarray(self.MNIST.targets[:N])
        self.noise = noise

        if aex_file is None:
            lst = []
            for i in range(len(self.MNIST)):
                xi, _ = self.MNIST[i]
                xi = xi.view(-1)
                if cfg['USE_CUDA']:
                    xi = xi.cuda()
                xi = ae_model(xi)
                xi = xi.detach().cpu().numpy().reshape(1, -1)
                lst.append(xi)
            xs0 = np.concatenate(lst, axis=0)
            xs0 = torch.from_numpy(xs0)
            # x = self.MNIST.data.type(torch.FloatTensor)
            # xs0 = ae_model((x-0.1307)/0.3081).detach().cpu().numpy()
            #self.ae_x = xs0
        else:
            xs0 = torch.load(aex_file)[:N]
            
        _mu = torch.mean(xs0, 0)
        _std = torch.std(xs0, 0)
        
        self.ae_x = (xs0-_mu)/_std

    def __getitem__(self, index):
        data, target = self.MNIST[index]
        data = data + (torch.rand(data.size()) - 0.5) * self.noise
        # Your transformations here (or set it in CIFAR10)
        return data, self.ae_x[index], target, index

    def __len__(self):
        return len(self.MNIST)


class InfiniteDataLoader(DataLoader):
    """
    reload the dataset from start when meets an end.
    """
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # Initialize an iterator over the dataset.
        self.dataset_iterator = super().__iter__()

    def __iter__(self):
        return self

    def __next__(self):
        try:
            batch = next(self.dataset_iterator)
        except StopIteration:
            # Dataset exhausted, use a new fresh iterator.
            self.dataset_iterator = super().__iter__()
            batch = next(self.dataset_iterator)
        return batch


def plot2tfimage(figure):
  """Converts the matplotlib plot specified by 'figure' to a PNG image and
  returns it. The supplied figure is closed and inaccessible after this call."""
  # Save the plot to a PNG in memory.
  buf = io.BytesIO()
  plt.savefig(buf, format='png')
  # Closing the figure prevents it from being displayed directly inside
  # the notebook.
  plt.close(figure)
  buf.seek(0)
  # Convert PNG buffer to TF image
  image = tf.image.decode_png(buf.getvalue(), channels=4)
  # Add the batch dimension
  image = tf.expand_dims(image, 0)
  return image


def show_clusters(K, ks, dataset, xs0, mu_K, W=28, H=28, k_lst=None):
    if k_lst == None:
        k_lst = range(K)
    for k in k_lst:
        print('Cluster %d:' % k)
        plt.imshow(np.asarray(mu_K[k]).reshape(W, H))
        plt.title('Centroid')
        plt.show()
        cnt = min(25, len(np.where(ks == k)[0]))
        idx = np.random.choice(np.where(ks == k)[0], cnt, replace=False)
        imgx = make_grid(dataset.MNIST.data[idx].view(-1, 1, W, H).float(), nrow=5, normalize=True).detach().numpy()
        imgz = make_grid(torch.from_numpy(xs0[idx]).view(-1, 1, W, H).float(), nrow=5, normalize=True).detach().numpy()
        #         imgx = 1.0*(imgx+np.min(imgx))/(np.max(imgx)-np.min(imgx))
        #         imgz = 1.0*(imgz+np.min(imgz))/(np.max(imgz)-np.min(imgz))
        plt.subplot(1, 2, 1)
        plt.imshow(np.transpose(imgx, (1, 2, 0)), interpolation='nearest')
        plt.title('Origin space')
        plt.subplot(1, 2, 2)
        plt.imshow(np.transpose(imgz, (1, 2, 0)), interpolation='nearest')
        plt.title('Transformed space')
        plt.show()


def sample_clusters(nK_total, ks, dataset, xs0, W=28, H=28, fig_size=8, cluster_idx_lst=None):
    N_CLASS = 15
    N_CLASS_SAMPLE = 9
    N_IMAGE_ROW = 3
    aeW = 2
    aeH = 5
    # time consuming operation
    if cluster_idx_lst is None:
        cluster_idx_lst = list(range(min(nK_total, N_CLASS)))

    figure = plt.figure()
    plt.subplots(nrows=len(cluster_idx_lst), ncols=3, figsize=(fig_size, fig_size * len(cluster_idx_lst) / 3))
    plt.tight_layout()
    ll = len(cluster_idx_lst)
    for _kid in range(ll):
        # 1. show cluster mean vector
        k = cluster_idx_lst[_kid]
        plt.title('k:%d/%d |C_k|=%d' % (k, nK_total, len(np.where(ks == k)[0])))

        # sample images idx from each cluster
        cnt = min(N_CLASS_SAMPLE, len(np.where(ks == k)[0]))
        idx = np.random.choice(np.where(ks == k)[0], cnt, replace=False)

        # 2. plot raw image
        imgx = make_grid(dataset.MNIST.data[idx].view(-1, 1, W, H).float(),
                         nrow=N_IMAGE_ROW, normalize=True
                         ).detach().numpy()
        plt.subplot(ll, 3, _kid * 3 + 2)
        plt.imshow(np.transpose(imgx, (1, 2, 0)), interpolation='nearest')
        plt.title('Origin space')

        # 3. plot flow repr of image
        image_z = torch.from_numpy(xs0[idx]).view(-1, 1, aeW, aeH).float()
        imgz = make_grid(image_z, nrow=N_IMAGE_ROW, normalize=True).detach().numpy()
        plt.subplot(ll, 3, _kid * 3 + 3)
        plt.imshow(np.transpose(imgz, (1, 2, 0)), interpolation='nearest')
        plt.title('Transformed space')

    # show image
    buf = io.BytesIO()
    plt.savefig(buf, format='png')
    plt.close(figure)
    buf.seek(0)
    # Convert PNG buffer to TF image
    image = tf.image.decode_png(buf.getvalue(), channels=4)
    # Add the batch dimension
    image = tf.expand_dims(image, 0)
    return image


def plt2img(pllt, figure):
    buf = io.BytesIO()
    pllt.savefig(buf, format='png')
    pllt.close(figure)
    buf.seek(0)
    # Convert PNG buffer to TF image
    image = tf.image.decode_png(buf.getvalue(), channels=4)
    # Add the batch dimension
    image = tf.expand_dims(image, 0)
    return image


def savefig_clusters(n_epoch, nK_total, ks, dataset, xs0, mu_K, path='./res', sz=8, phase=1,
                     datasetname='mnist', cluster_idx_lst=None, plot=False, model=None, tensor_board=True):
    if datasetname == 'mnist':
        W, H, aeW, aeH = 28, 28, 2, 5
    elif datasetname == 'cifar10':
        W, H, aeW, aeH = 32, 32, 6, 8

    N_CLASS = 15
    N_CLASS_SAMPLE = 9
    N_IMAGE_ROW = 3
    # time consuming operation
    if cluster_idx_lst is None:
        cluster_idx_lst = list(range(min(nK_total, N_CLASS)))

    figure = plt.figure()
    plt.subplots(nrows=len(cluster_idx_lst), ncols=3, figsize=(sz, sz * len(cluster_idx_lst) / 3))
    plt.tight_layout()
    ll = len(cluster_idx_lst)
    for _kid in range(ll):
        # 1. show cluster mean vector
        k = cluster_idx_lst[_kid]
        plt.subplot(ll, 3, _kid * 3 + 1)
        plt.imshow(np.asarray(mu_K[k]).reshape(aeW, aeH))
        plt.colorbar()
        plt.title('k:%d/%d |C_k|=%d' % (k, nK_total, len(np.where(ks == k)[0])))

        # sample images idx from each cluster
        cnt = min(N_CLASS_SAMPLE, len(np.where(ks == k)[0]))
        idx = np.random.choice(np.where(ks == k)[0], cnt, replace=False)

        # 2. plot raw image
        imgx = make_grid(dataset.data[idx].view(-1, 1, W, H).float(), nrow=N_IMAGE_ROW, normalize=True).detach().numpy()
        plt.subplot(ll, 3, _kid * 3 + 2)
        plt.imshow(np.transpose(imgx, (1, 2, 0)), interpolation='nearest')
        plt.title('Origin space')

        # 3. plot flow repr of image
        if xs0 is None:
            image_z = [model.cpu().f(dataset[_idx][0].view(-1)).view(1, aeW, aeH).float() for _idx in idx]
        else:
            image_z = torch.from_numpy(xs0[idx]).view(-1, 1, aeW, aeH).float()
        imgz = make_grid(image_z, nrow=N_IMAGE_ROW, normalize=True).detach().numpy()
        plt.subplot(ll, 3, _kid * 3 + 3)
        plt.imshow(np.transpose(imgz, (1, 2, 0)), interpolation='nearest')
        plt.title('Transformed space')

    # show image
    if tensor_board:
        buf = io.BytesIO()
        plt.savefig(buf, format='png')
        plt.close(figure)
        buf.seek(0)
        # Convert PNG buffer to TF image
        image = tf.image.decode_png(buf.getvalue(), channels=4)
        # Add the batch dimension
        image = tf.expand_dims(image, 0)
        return image
    elif plot:
        plt.show()
        plt.close(figure)
    elif path is not None:
        plt.savefig('%s/%s_phase%d_epoch%d.png' % (path, datasetname, phase, n_epoch))
        plt.close(figure)


def transform_z(model, dataset, N, idx=None, xs0=None, _n=5000, normalize=False):
    s = time.time()
    model.cuda().eval()
    if idx is None:
#         xs0 = model.f(dataset.ae_x)[0].detach().cpu().numpy()
        lst = []
        xs0 = dataset
        for b in range(N):
            _, xi, _, _ = xs0[b]
            xi = xi.view(-1)
            xi = xi.cuda()
            xi, _ = model.f(xi)
            xi = xi.detach().cpu().numpy().reshape(1, -1)
            lst.append(xi)
        xs0 = np.concatenate(lst, axis=0)

    print(f'transfrom consumed {time.time()-s:.1f}s')
    return xs0


# def transform_ae(model, data, N):
#     xs0 = data
#     lst = []
#     for b in range(N):
#         xi, _, _ = xs0[b]
#         xi = xi.view(-1)
#         if cfg['USE_CUDA']: xi = xi.cuda()
#         xi, _ = model(xi)
#         xi = xi.detach().cpu().numpy().reshape(1,-1)
#         mu = np.mean(xi)
#         sig = np.std(xi)
#         xi = (xi-mu)/sig
#         lst.append(xi)
#     xs0 = np.concatenate(lst, axis=0)
#     return xs0

def mvnrvs(mu, sig2):
    """multi-variant normal random variables"""
    sig = np.sqrt(sig2)
    d = len(mu)
    res = np.random.randn(d) * sig + mu
    return res


def mvnlogpdf(x, mu, sig2):
    """multi-variant normal log probability density fucntion"""
    sig = np.sqrt(sig2)
    d = len(mu)
    res = -0.5 * d * log(2 * pi * sig2) - 0.5 * np.sum((x - mu) ** 2) / sig2
    return res